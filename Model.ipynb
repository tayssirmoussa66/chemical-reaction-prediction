{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkVPTPyGYHaB",
        "outputId": "26652008-febd-484b-8d1e-c1bd869e3361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'reaction_dataset'...\n",
            "remote: Enumerating objects: 41251, done.\u001b[K\n",
            "remote: Counting objects: 100% (453/453), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 41251 (delta 441), reused 447 (delta 435), pack-reused 40798\u001b[K\n",
            "Receiving objects: 100% (41251/41251), 135.55 MiB | 19.48 MiB/s, done.\n",
            "Resolving deltas: 100% (41103/41103), done.\n",
            "Checking out files: 100% (41200/41200), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tayssirmoussa66/reaction_dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1Ih1eDWbNCP"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size, n_layers, embedding_size, n_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "           \n",
        "        # construct input layer\n",
        "        self.layers.append(GraphConv(feature_size, embedding_size))\n",
        "        # construct hidden layers\n",
        "        for i in range(n_layers -1):\n",
        "            self.layers.append(GraphConv(embedding_size, embedding_size))\n",
        "\n",
        "        self.att_layer = GATConv(embedding_size, embedding_size,heads=n_heads, \n",
        "                                    )\n",
        "        \n",
        "        self.linear1 = Linear(embedding_size, feature_size)\n",
        "        \n",
        "\n",
        "        self.Linear2 = Linear(embedding_size*n_heads, embedding_size)\n",
        "        self.Linear3 = Linear(embedding_size*2, embedding_size)\n",
        "\n",
        "        self.out_Layer= MLP(in_channels=feature_size*2, hidden_channels=10,\n",
        "          out_channels=5, num_layers=6)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, edge_weight, edge_index):\n",
        "        #Local embeddings \n",
        "        for layer in self.layers:\n",
        "            x = layer( x, edge_index, edge_weight)\n",
        "            x = F.relu(x)\n",
        "        \n",
        "         #attention layer\n",
        "        \n",
        "        y = self.att_layer(x, edge_index)\n",
        "        y = self.relu(self.Linear2(y))\n",
        "        y = F.dropout(y, p=0.6, training=self.training)\n",
        "\n",
        "        #Global embeddings\n",
        "        \n",
        "        concat_vector = torch.cat([x, y], 1)\n",
        "        concat_vector=self.Linear3(concat_vector)\n",
        "\n",
        "\n",
        "        x = self.relu(self.linear1 (concat_vector))\n",
        "\n",
        "        out = self.relu(self.out_Layer(torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=-1)))\n",
        "\n",
        "        return out\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dp7SWJRapTHl",
        "outputId": "3db7f55f-de4d-41f9-b421-58385365ac9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 12.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 40.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 50.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 32.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 64.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 46.8 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUo8vctCpYTr",
        "outputId": "08dde8bd-36b3-44c2-8715-0a06355232c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 36.8 MB 1.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install rdkit-pypi -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaHnRr4Upf9j",
        "outputId": "25ce1127-0cf0-4938-c18c-cca500299f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 11.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 12.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 12.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 13.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 17.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0-py3-none-any.whl size=687167 sha256=6e804f35b3fe1f0097cf13b65df6a6bbd6eec4a54a9db22bc7ebf41179adc91c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9b/21/7a21b39bcea8f520c9cf2f0eca06e97cd81d02b0ef42ce4942\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifwTuWBCpMXe"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "import torch\n",
        "from torch.nn import Linear, BatchNorm1d, ModuleList, Softmax\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset, Data, Batch, download_url\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "from torch_geometric.loader import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.nn import GraphConv,GATConv, MLP\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
        "    accuracy_score, precision_score, recall_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTVZxRnLYLBz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8Xbx8_MX9ot"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename=\"/content/sample_data/my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    idx= checkpoint[\"batch_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv38NJkSzGDh"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size, n_layers, embedding_size, n_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "           \n",
        "        # construct input layer\n",
        "        self.layers.append(GraphConv(feature_size, embedding_size))\n",
        "        # construct hidden layers\n",
        "        for i in range(n_layers -1):\n",
        "            self.layers.append(GraphConv(embedding_size, embedding_size))\n",
        "\n",
        "        self.att_layer = GATConv(embedding_size, embedding_size,heads=n_heads, \n",
        "                                    )\n",
        "        self.linear1 = Linear(embedding_size, feature_size)\n",
        "        \n",
        "\n",
        "        self.Linear2 = Linear(embedding_size*n_heads, embedding_size)\n",
        "        self.Linear3 = Linear(embedding_size*2, embedding_size)\n",
        "\n",
        "        self.out_Layer= MLP(in_channels=feature_size*2, hidden_channels=28,\n",
        "          out_channels=5, num_layers=3)\n",
        "        \n",
        "\n",
        "    def forward(self, x, edge_weight, edge_index):\n",
        "        #Local embeddings \n",
        "        for layer in self.layers:\n",
        "            x = layer( x, edge_index, edge_weight)\n",
        "            x = F.relu(x)\n",
        "        \n",
        "         #attention layer\n",
        "        \n",
        "        y = self.att_layer(x, edge_index)\n",
        "        y = F.elu(self.Linear2(y))\n",
        "        y = F.dropout(y, p=0.6, training=self.training)\n",
        "\n",
        "        #Global embeddings\n",
        "        Global = F.log_softmax(y, dim=1)\n",
        "        concat_vector = torch.cat([x, Global], 1)\n",
        "        concat_vector=self.Linear3(concat_vector)\n",
        "\n",
        "\n",
        "        x = self.linear1 (concat_vector)\n",
        "\n",
        "        out = self.out_Layer(torch.cat([x[edge_index[0]], x[edge_index[1]]], dim=-1))\n",
        "\n",
        "        return out\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYLs_5r8zIwu"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import MultiStepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yncwKNvZvFeU",
        "outputId": "09efc800-1026-41b0-dcc1-4f8f1f004882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting class-resolver\n",
            "  Downloading class_resolver-0.3.10-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: class-resolver\n",
            "Successfully installed class-resolver-0.3.10\n"
          ]
        }
      ],
      "source": [
        "pip install class-resolver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh3AjTaaeUSI",
        "outputId": "9a744728-558e-42c9-9af5-5d65dd12a7e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n"
          ]
        }
      ],
      "source": [
        "# Loading the model\n",
        "print(\"Loading model...\")\n",
        "\n",
        "loss_fn= torch.nn.CrossEntropyLoss()\n",
        "model = GCN(feature_size=7, n_layers=10, embedding_size=100, n_heads=5) \n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr = 0.01 )\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones = [400, 450], gamma = 0.1, verbose = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDpKUCsY7WOs",
        "outputId": "910a63b1-ed9d-4607-bf6b-9de3c935892a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (layers): ModuleList(\n",
              "    (0): GraphConv(7, 100)\n",
              "    (1): GraphConv(100, 100)\n",
              "    (2): GraphConv(100, 100)\n",
              "    (3): GraphConv(100, 100)\n",
              "    (4): GraphConv(100, 100)\n",
              "    (5): GraphConv(100, 100)\n",
              "    (6): GraphConv(100, 100)\n",
              "    (7): GraphConv(100, 100)\n",
              "    (8): GraphConv(100, 100)\n",
              "    (9): GraphConv(100, 100)\n",
              "  )\n",
              "  (att_layer): GATConv(100, 100, heads=5)\n",
              "  (linear1): Linear(in_features=100, out_features=7, bias=True)\n",
              "  (Linear2): Linear(in_features=500, out_features=100, bias=True)\n",
              "  (Linear3): Linear(in_features=200, out_features=100, bias=True)\n",
              "  (out_Layer): MLP(14, 28, 28, 5)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5REcmtwIzBik",
        "outputId": "a32d41c0-a788-400b-e7d8-8d1aebe0f1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda available: False\n"
          ]
        }
      ],
      "source": [
        "print(f\"Cuda available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEWNB4Sj_UfM"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_pred, y_true, epoch):\n",
        "   \n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='micro')}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "    prec = precision_score(y_true, y_pred, average='micro')\n",
        "    rec = recall_score(y_true, y_pred, average='micro')\n",
        "    print(f\"Precision: {prec}\")\n",
        "    print(f\"Recall: {rec}\")\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5-1gWnTyjr0"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch( model,path, optimizer, loss_fn):\n",
        "    running_loss = 0.0\n",
        "    step = 0\n",
        "   \n",
        "   \n",
        "    for i in range(400):\n",
        "\n",
        "        data = torch.load(osp.join(path,f'data_{i}.pt'))    \n",
        "         # Use GPU\n",
        "        data.to(device)\n",
        "        # Reset gradients\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        # Passing the node features and the connection info\n",
        "        \n",
        "        output = model(data.x.float(), \n",
        "                                data.edge_weight.float(),\n",
        "                                \n",
        "                                data.edge_index,   \n",
        "                                ) \n",
        "            \n",
        "        # Calculating the loss and gradients\n",
        "\n",
        "        loss = loss_fn(torch.abs(output), data.y)\n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "\n",
        "        # Update tracking\n",
        "        running_loss += loss.item()\n",
        "        step += 1\n",
        "           \n",
        "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "    return running_loss/step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftXRkFDpotQe"
      },
      "outputs": [],
      "source": [
        "def test(epoch, model, path, loss_fn):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    running_loss = 0.0\n",
        "    step = 0\n",
        "\n",
        "    for i in range(400,499):\n",
        "\n",
        "        data = torch.load(osp.join(path,f'data_{i}.pt'))   \n",
        "        data.to(device)\n",
        "        output = model(data.x.float(), \n",
        "                                data.edge_weight.float(),\n",
        "                                data.edge_index,   \n",
        "                                ) \n",
        "      \n",
        "        loss =  loss_fn(torch.abs(output), data.y.type(torch.float))\n",
        "         # Update tracking\n",
        "        running_loss += loss.item()\n",
        "        step += 1\n",
        "\n",
        "        all_preds.append(np.rint(torch.abs(output).cpu().detach().numpy()))\n",
        "\n",
        "        all_labels.append(data.y.cpu().detach().numpy())\n",
        "    \n",
        "    all_preds = np.concatenate(all_preds).ravel()\n",
        "    all_labels = np.concatenate(all_labels).ravel()\n",
        "    \n",
        "    print(np.unique(all_preds, return_counts =True))\n",
        "    print(np.unique(all_labels, return_counts =True))\n",
        " \n",
        "    calculate_metrics(all_preds, all_labels, epoch)\n",
        "    \n",
        "    return running_loss/step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ajUHWczo2P",
        "outputId": "8dfbc2b7-dfa6-4dc7-879b-0ea53586d916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Epoch 0 | Train Loss 2.007393551617245e-09\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 0 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 1 | Train Loss 1.9132314372749745e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 2 | Train Loss 1.6527316457097567e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 3 | Train Loss 1.1194434458830128e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 4 | Train Loss 1.2446396645457302e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 5 | Train Loss 4.1284584128922846e-10\n",
            "(array([ 0., 17., 18.], dtype=float32), array([745308,  63957, 122370]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 5 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 6 | Train Loss 6.348107713359251e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 7 | Train Loss 8.791430650987401e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 8 | Train Loss 1.4061197889496878e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 9 | Train Loss 5.400450342232167e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 10 | Train Loss 2.8159774448043827e-10\n",
            "(array([ 0., 18., 19.], dtype=float32), array([745308,  44001, 142326]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 10 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 11 | Train Loss 3.36668660919869e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 12 | Train Loss 1.7338945400733918e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 13 | Train Loss 4.467540429506322e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 14 | Train Loss 2.6753104856255674e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 15 | Train Loss 2.637949303877661e-10\n",
            "(array([ 0., 17.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 15 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 16 | Train Loss 2.472366044327901e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 17 | Train Loss 2.5627043906914515e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 18 | Train Loss 3.027476893874615e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 19 | Train Loss 2.2190218530045732e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 20 | Train Loss 1.8070860859002567e-10\n",
            "(array([ 0., 17.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 20 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 21 | Train Loss 2.0842504131321098e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 22 | Train Loss 2.3149429995250685e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 23 | Train Loss 2.0816041170055337e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 24 | Train Loss 1.4519972743995018e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 25 | Train Loss 1.862840345597381e-10\n",
            "(array([ 0., 17.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 25 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 26 | Train Loss 2.5073515759789645e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 27 | Train Loss 1.690283086297848e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 28 | Train Loss 1.2318292519353236e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 29 | Train Loss 4.4695194502490193e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 30 | Train Loss 0.0\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 30 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 31 | Train Loss 7.323970715547319e-11\n",
            "=> Saving checkpoint\n",
            "Epoch 32 | Train Loss 4.223016840412587e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 33 | Train Loss 8.20004628564457e-11\n",
            "=> Saving checkpoint\n",
            "Epoch 34 | Train Loss 6.3484221903056e-11\n",
            "=> Saving checkpoint\n",
            "Epoch 35 | Train Loss 1.4833503156836612e-10\n",
            "(array([ 0., 17.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 35 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 36 | Train Loss 2.1219404987737504e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 37 | Train Loss 1.9874688210335741e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 38 | Train Loss 4.3721004342662294e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 39 | Train Loss 1.8160785875132034e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 40 | Train Loss 0.0\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 40 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 41 | Train Loss 2.9802315282267954e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 42 | Train Loss 2.8610222670977236e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 43 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 44 | Train Loss 2.037267646248786e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 45 | Train Loss 6.285604502216197e-10\n",
            "(array([ 0., 21.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 45 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 46 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 47 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 48 | Train Loss 5.929527104460483e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 49 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 50 | Train Loss 2.980232061133847e-10\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 50 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 51 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 52 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 53 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 54 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 55 | Train Loss 0.0\n",
            "(array([ 0., 17.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 55 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 56 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 57 | Train Loss 5.960463766996327e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 58 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 59 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 60 | Train Loss 0.0\n",
            "(array([ 0., 17.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 60 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 61 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 62 | Train Loss 5.960463766996327e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 63 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 64 | Train Loss 8.940695295223123e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 65 | Train Loss 0.0\n",
            "(array([ 0., 20.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 65 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 66 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 67 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 68 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 69 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 70 | Train Loss 2.980232061133847e-10\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 70 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 71 | Train Loss 8.940695295223123e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 72 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 73 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 74 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 75 | Train Loss 2.980232061133847e-10\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 75 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 76 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 77 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 78 | Train Loss 5.960463766996327e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 79 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 80 | Train Loss 0.0\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 80 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 81 | Train Loss 5.960463766996327e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 82 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 83 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 84 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 85 | Train Loss 2.980232061133847e-10\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 85 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 86 | Train Loss 1.1920926112907182e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 87 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 88 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 89 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 90 | Train Loss 2.980232061133847e-10\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 90 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 91 | Train Loss 1.1920926112907182e-09\n",
            "=> Saving checkpoint\n",
            "Epoch 92 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 93 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 94 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 95 | Train Loss 2.980232061133847e-10\n",
            "(array([ 0., 18.], dtype=float32), array([745308, 186327]))\n",
            "(array([0., 1.]), array([745308, 186327]))\n",
            "F1 Score: 0.8000000000000002\n",
            "Accuracy: 0.8\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "Epoch 95 | Test Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 96 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 97 | Train Loss 0.0\n",
            "=> Saving checkpoint\n",
            "Epoch 98 | Train Loss 2.980232061133847e-10\n",
            "=> Saving checkpoint\n",
            "Epoch 99 | Train Loss 2.980232061133847e-10\n"
          ]
        }
      ],
      "source": [
        "for epoch in range (100):\n",
        "   model.train()\n",
        "   loss = train_one_epoch( model,'/content/reaction_dataset/Train_Data', optimizer,loss_fn)\n",
        "   print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
        "   model.eval()\n",
        "   if epoch % 5 == 0:\n",
        "      loss = test(epoch, model,'/content/reaction_dataset/Train_Data',loss_fn)\n",
        "      print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
        "      scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}